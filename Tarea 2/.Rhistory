data<-read.csv("dataTrain.csv")
View(data)
Tuplas_na<-sum(apply(X=is.na(data),MARGIN=1,FUN =sum)>0)
Tuplas_na
#columnas con nulos:
Column_na<-sum(apply(X=is.na(data),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
test<-read.csv("dataEval.csv")
View(test)
#Viendo nulos de Eval: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col].order
order(apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col])
apply(X=is.na(data),MARGIN=2,FUN =sum)[order(valores_col)]
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
apply(X=is.na(test),MARGIN=2,FUN =sum)[order(valores_col)]
clean
\clean
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
apply(X=is.na(test),MARGIN=2,FUN =sum)[order(valores_col)]
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
apply(X=is.na(test),MARGIN=2,FUN =sum)[order(valores_col)]
apply(X=is.na(test),MARGIN=2,FUN =sum)[order(-valores_col)]
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>=0
apply(X=is.na(test),MARGIN=2,FUN =sum)[order(valores_col)]
## Viendo nulos de Eval: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
data<-read.csv("dataTrain.csv")
test<-read.csv("dataEval.csv")
## Viendo nulos de Eval: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>=0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>=0
apply(X=is.na(test),MARGIN=2,FUN =sum)[order(valores_col)]
valores_col
order(apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col])
apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
data<-read.csv("dataTrain.csv")
test<-read.csv("dataEval.csv")
## Viendo nulos de Eval: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
## Viendo nulos de Train: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(data),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(data),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
a<-apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
a
a[1]
a.names()
names(a)
apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
a<-apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]>37500
names(a)
a<-
Eval_nulos<-names(apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]>37500)
## Viendo nulos de Train: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(data),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(data),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
Col_Train_nulos<-names(apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]>99500)
Col_Train_nulos
Col_Train_nulos<-names(apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]>99500)
Col_Train_nulos
apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]>37500
a<-apply(X=is.na(test),MARGIN=2,FUN =sum)[valore_col]
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
a<-apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
Col_Eval_nulos<-names(a[a>37500])
Col_Eval_nulos
a
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
b<-apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
b
Col_Train_nulos<-names(b[b>99500])
Col_Train_nulos
data<-read.csv("dataTrain.csv")
test<-read.csv("dataEval.csv")
## Viendo nulos de Eval: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
a<-apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
a
Col_Eval_nulos<-names(a[a>37500])
Col_Eval_nulos
apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]>37500
## Viendo nulos de Train: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(data),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(data),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
b<-apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
b
Col_Train_nulos<-names(b[b>99500])
Col_Train_nulos
data<-read.csv("dataTrain.csv")
test<-read.csv("dataEval.csv")
## Viendo nulos de Eval: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
a<-apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
a
Col_Eval_nulos<-names(a[a>37500])
Col_Eval_nulos
## Viendo nulos de Train: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(data),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(data),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
b<-apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
b
Col_Train_nulos<-names(b[b>99500])
Col_Train_nulos
data<-data[-["G","GM","BV","UB","IR"]]
data<-data[-c("G","GM","BV","UB","IR")]
data<-data[!c("G","GM","BV","UB","IR")]
data<-data[select(-c("G","GM","BV","UB","IR"))]
install.packages("devtools")
data<-data[select(-c("G","GM","BV","UB","IR"))]
library(EDAWR)
install.packages("devtools","EDWAR")
library(devtools)
data<-data[select(-c("G","GM","BV","UB","IR"))]
select(-c("G","GM","BV","UB","IR")
select(-c("G","GM","BV","UB","IR"))
select(-c("G","GM","BV","UB","IR"))
for (i in Col_Train_nulos){
data$i<-NULL
}
for (i in Col_Train_nulos){
data$i<-NULL
}
data
data$i
print(i)
for (i in Col_Train_nulos){
print(i)
data$i<-NULL
}
data$G<-NULL
data$GM<-NULL
data$BV<-NULL
data$UB<-NULL
data$IR<-NULL
Tuplas_na #Todas las tuplas tienen nulos
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(data),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
b<-apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
b
#Siguen habiendo 99970 tuplas con nulos.
str(data)
#columnas con nulos:
Column_na<-sum(apply(X=is.na(data),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
b<-apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
b
data<-read.csv("dataTrain.csv")
test<-read.csv("dataEval.csv")
#columnas con nulos:
Column_na<-sum(apply(X=is.na(data),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
b<-apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
b
install.packages("devtools")
pacman::p_load(psych,ggplot2,tidyverse,proxy,dplyr)
data<-read.csv("dataTrain.csv")
test<-read.csv("dataEval.csv")
## Viendo nulos de Eval: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
a<-apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
a
Col_Eval_nulos<-names(a[a>37500])
Col_Eval_nulos
## Viendo nulos de Train: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(data),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(data),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
b<-apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
b
Col_Train_nulos<-names(b[b>99500])
Col_Train_nulos
#Elimnamos las columnas con mayor cantidad de nulos.
data$G<-NULL
data$GM<-NULL
data$BV<-NULL
data$UB<-NULL
data$IR<-NULL
#Siguen habiendo 99970 tuplas con nulos.
str(data)
#Variable a predecir:
summary(data["diameter"])
hist(data["diameter"])
hist(x=data$diameter)
?hist
boxplot(x=data$diameter)
#Variable a predecir:
summary(data["diameter"])
hist(x=test$diameter)
hist(x=data$diameter)
boxplot(x=data$diameter)
algo<-data[data["diameter"]>200]
algo
algo<-data$diameter[data["diameter"]>200]
algo<-data$diameter[data["diameter"]>100]
algo<-data$diameter[data["diameter"]>90]
algo<-data$diameter[data["diameter"]>30]
algo<-data$diameter[data["diameter"]>20]
algo<-data$diameter[data["diameter"]>10]
algo<-data$diameter[data["diameter"]>5]
algo<-data$diameter[data["diameter"]>200]
# Analisis Descriptivo ####
str(data)
#Variable a predecir:
summary(data["diameter"])
pacman::p_load(psych,ggplot2,tidyverse,proxy,dplyr)
data<-read.csv("dataTrain.csv")
test<-read.csv("dataEval.csv")
## Viendo nulos de Eval: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
a<-apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
a
Col_Eval_nulos<-names(a[a>37500])
Col_Eval_nulos
## Viendo nulos de Train: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(data),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(data),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
b<-apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
b
Col_Train_nulos<-names(b[b>99500])
Col_Train_nulos
#Eliminamos los indices:
data$X<-NULL
data$index<-NULL
data$full_name<-NULL
#Elimnamos las columnas con mayor cantidad de nulos.
data$G<-NULL
data$GM<-NULL
data$BV<-NULL
data$UB<-NULL
data$IR<-NULL
#Siguen habiendo 99970 tuplas con nulos.
# Analisis Descriptivo ####
str(data)
nombres<-names(select_if(data, is.numeric))
nombres
medias<-c(mean(data$a,na.rm = TRUE),mean(data$e,na.rm = TRUE),mean(data$i,na.rm = TRUE)
,mean(data$om,na.rm = TRUE),mean(data$w,na.rm = TRUE),mean(data$q,na.rm = TRUE)
,mean(data$ad,na.rm = TRUE),mean(data$per_y,na.rm = TRUE),mean(data$data_arc,na.rm = TRUE)
,mean(data$condition_code,na.rm = TRUE),mean(data$n_obs_used,na.rm = TRUE)
,mean(data$H,na.rm = TRUE),mean(data$diameter,na.rm = TRUE),mean(data$albedo,na.rm = TRUE)
,mean(data$rot_per,na.rm = TRUE),mean(data$moid,na.rm = TRUE))
#guardamos data con nulos:
data2=data
#Remplazar los nulos con la media.
for (i in 1:16){
variable=nombres[i]
data[[variable]]<- round(data[[variable]] %>%
replace(is.na(.),medias[i]), digits = 6)
}
#columnas con su respectivo numero de nulos
apply(X=is.na(data),MARGIN=2,FUN =sum)
#Correlaciones
muestra<-select_if(data,is.numeric)
#Menor a mayor considerando negativos:
cor(muestra, method="pearson")[13,][order(cor(muestra, method="pearson")[15,])]
#Menor a mayor en absoluto:
sort(abs(cor(muestra, method="pearson")[13,]))
sort(abs(cor(muestra, method="spearman")[13,]))
data$rot_per<-NULL
#Borramos data con correlacion bajo 0.2 en pearson y 0.3 en spearmann
data$w<-NULL
data$rot_per<-NULL
data$om<-NULL
data$e<-NULL
data$i<-NULL
data$albedo<-NULL
data$condition_code<-NULL
muestra<-select_if(data,is.numeric)
sort(abs(cor(muestra, method="pearson")[13,]))
sort(abs(cor(muestra, method="pearson")[6,]))
sort(abs(cor(muestra, method="pearson")[5,]))
sort(abs(cor(muestra, method="pearson")[4,]))
sort(abs(cor(muestra, method="pearson")[1,]))
sort(abs(cor(muestra, method="pearson")[2,]))
sort(abs(cor(muestra, method="pearson")[3,]))
sort(abs(cor(muestra, method="pearson")[4,]))
sort(abs(cor(muestra, method="pearson")[5,]))
sort(abs(cor(muestra, method="pearson")[6,]))
sort(abs(cor(muestra, method="pearson")[7,]))
sort(abs(cor(muestra, method="pearson")[8,]))
sort(abs(cor(muestra, method="pearson")[8,]))
sort(abs(cor(muestra, method="spearman")[8,]))
#Borramos variables categoricas que no afectan a nuestro.
data$neo<-NULL
data$pha<-NULL
data$extent<-NULL
pacman::p_load(psych,ggplot2,tidyverse,proxy,dplyr)
data<-read.csv("dataTrain.csv")
test<-read.csv("dataEval.csv")
## Viendo nulos de Eval: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(test),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(test),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(test),MARGIN=2,FUN =sum)>0
a<-apply(X=is.na(test),MARGIN=2,FUN =sum)[valores_col]
a
Col_Eval_nulos<-names(a[a>37500])
Col_Eval_nulos
## Viendo nulos de Train: ####
#Tuplas con nulos:
Tuplas_na<-sum(apply(X=is.na(data),MARGIN=1,FUN =sum)>0)
Tuplas_na #Todas las tuplas tienen nulos
#columnas con nulos:
Column_na<-sum(apply(X=is.na(data),MARGIN=2,FUN =sum)>0)
#columnas con su respectivo numero de nulos
valores_col<-apply(X=is.na(data),MARGIN=2,FUN =sum)>0
b<-apply(X=is.na(data),MARGIN=2,FUN =sum)[valores_col]
b
Col_Train_nulos<-names(b[b>99500])
Col_Train_nulos
#Eliminamos los indices:
data$X<-NULL
data$index<-NULL
data$full_name<-NULL
#Elimnamos las columnas con mayor cantidad de nulos.
data$G<-NULL
data$GM<-NULL
data$BV<-NULL
data$UB<-NULL
data$IR<-NULL
#Borramos variables categoricas que no afectan a nuestro.
data$neo<-NULL
data$pha<-NULL
data$extent<-NULL
data$spec_B<-NULL
data$spec_T<-NULL
#Siguen habiendo 99970 tuplas con nulos.
# Analisis Descriptivo ####
str(data)
nombres<-names(select_if(data, is.numeric))
nombres
medias<-c(mean(data$a,na.rm = TRUE),mean(data$e,na.rm = TRUE),mean(data$i,na.rm = TRUE)
,mean(data$om,na.rm = TRUE),mean(data$w,na.rm = TRUE),mean(data$q,na.rm = TRUE)
,mean(data$ad,na.rm = TRUE),mean(data$per_y,na.rm = TRUE),mean(data$data_arc,na.rm = TRUE)
,mean(data$condition_code,na.rm = TRUE),mean(data$n_obs_used,na.rm = TRUE)
,mean(data$H,na.rm = TRUE),mean(data$diameter,na.rm = TRUE),mean(data$albedo,na.rm = TRUE)
,mean(data$rot_per,na.rm = TRUE),mean(data$moid,na.rm = TRUE))
#guardamos data con nulos:
data2=data
#Remplazar los nulos con la media.
for (i in 1:16){
variable=nombres[i]
data[[variable]]<- round(data[[variable]] %>%
replace(is.na(.),medias[i]), digits = 6)
}
#columnas con su respectivo numero de nulos
apply(X=is.na(data),MARGIN=2,FUN =sum)
#Correlaciones
muestra<-select_if(data,is.numeric)
#Menor a mayor considerando negativos:
cor(muestra, method="pearson")[13,][order(cor(muestra, method="pearson")[15,])]
#Menor a mayor en absoluto:
sort(abs(cor(muestra, method="pearson")[13,]))
sort(abs(cor(muestra, method="spearman")[13,]))
#Borramos data con correlacion bajo 0.2 en pearson y 0.3 en spearmann
data$w<-NULL
data$rot_per<-NULL
data$om<-NULL
data$e<-NULL
data$i<-NULL
data$albedo<-NULL
data$condition_code<-NULL
muestra<-select_if(data,is.numeric)
sort(abs(cor(muestra, method="pearson")[8,]))
sort(abs(cor(muestra, method="spearman")[8,]))
write.csv(Data, file="data_nulos_media.csv")
write.csv(data, file="data_nulos_media.csv")
summary(data["diameter"][algo])
hist(x=data$diameter[algo])
algo<-data$diameter[data["diameter"]<100]
print(length(algo))
summary(data["diameter"][algo])
hist(x=data$diameter[algo])
hist(x=algo)
algo<-data$diameter[data["diameter"]<40]
hist(x=algo)
algo<-data$diameter[data["diameter"]<30]
print(length(algo))
summary(data["diameter"][algo])
hist(x=algo)
algo<-data$diameter[data["diameter"]<20]
hist(x=algo)
print(length(algo))
summary(algo)
summary(data$diameter)
